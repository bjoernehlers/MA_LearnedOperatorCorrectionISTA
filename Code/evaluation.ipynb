{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ray_transforms import get_ray_trafo, get_static_ray_trafo\n",
    "from test_model_functions_swaped import get_net_corected_operator\n",
    "# import random\n",
    "import torch \n",
    "\n",
    "\n",
    "import os\n",
    "from conf import config\n",
    "from select_model_type_matrix import select_fwd_model_type,select_adj_model_type\n",
    "from scipy import sparse\n",
    "from util import get_op,Mat,plots,rand_shift_params,error_for_y,check_path\n",
    "\n",
    "def im_norm(x):\n",
    "    x = x.reshape(x.size)\n",
    "    return np.linalg.norm(x,2)\n",
    "\n",
    "def sp(a,b):\n",
    "    return a.reshape(a.size)@b.reshape(b.size)\n",
    "\n",
    "def ISTA_obj_func(op,y,lam,x):\n",
    "    return 1/(2*lam)*np.linalg.norm((op(x)-y).reshape(y.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "\n",
    "def Test_PGM(step_op,L,grad_R,true_op,p,y_e,x_0_selector,test_op,mu,num_iter):\n",
    "    F_abl = lambda x: test_op.adjoint(test_op(x)-y_e) + grad_R(x)\n",
    "    F_true_abl = lambda x: true_op.adjoint(true_op(x)-y_e) + grad_R(x)\n",
    "    x = x_0_selector(y_e)\n",
    "    X = np.zeros((num_iter + 1,x.shape[0],x.shape[1]))\n",
    "    X[0] = x\n",
    "    loss = np.zeros(num_iter+1)\n",
    "    loss[0] = im_norm(p-x)\n",
    "    TThetaMu = np.zeros(num_iter)\n",
    "    LL = np.zeros(num_iter)\n",
    "    AL = np.zeros(num_iter)\n",
    "    FwL = np.zeros(num_iter)\n",
    "    AdL = np.zeros(num_iter)\n",
    "    for i in range(num_iter):\n",
    "        x_old = x\n",
    "        x = step_op(x,F_abl(x))\n",
    "        X[i+1] = x\n",
    "        loss[i+1] = im_norm(p-x)\n",
    "        T_Thetamu = (x_old-x)/(mu)\n",
    "        TThetaMu[i] = im_norm(T_Thetamu)\n",
    "        LL[i] = L(x_old)-L(x)\n",
    "        AL[i] = mu*(sp(F_true_abl(x_old)-F_abl(x_old),T_Thetamu)+0.5*TThetaMu[i]**2)\n",
    "        FwL[i] = im_norm(true_op(x)-test_op(x))\n",
    "        r = test_op(x)-y_e\n",
    "        AdL[i] = im_norm(true_op.adjoint(r)-test_op.adjoint(r))\n",
    "    X = X[np.arange(9,num_iter,10)]\n",
    "    return {'X':X,'loss':loss,'TThetaMu':TThetaMu,'LL':LL,'AL':AL,'FwL':FwL,'AdL':AdL}\n",
    "\n",
    "def Test_GD(step_op,L,grad_R,true_op,p,y_e,x_0_selector,test_op,mu,num_iter):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        step_op (_type_): an operator that produces the next iteration x_k+1 = step_op(x_k,F(x_k))\n",
    "        L (_type_): The objective function that is minimized for testing only\n",
    "        grad_R (_type_): the differentialle part of the regularization terms\n",
    "        true_op (_type_): the precise operator we try to achieve\n",
    "        p (_type_): the phantom\n",
    "        y_e (_type_): noisy data\n",
    "        x_0_selector (_type_): function that gives the x_0 deppending on y_e\n",
    "        test_op (_type_): the operaator we want to test\n",
    "        adj_test_op (_type_): the adjoint of the test opeartor\n",
    "        mu (_type_): constant step size for \n",
    "        num_iter (_type_): number of iterations taht are being computed\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    F_abl = lambda x: test_op.adjoint(test_op(x)-y_e) + grad_R(x)\n",
    "    F_true_abl = lambda x: true_op.adjoint(true_op(x)-y_e) + grad_R(x)\n",
    "    x = x_0_selector(y_e)\n",
    "    X = np.zeros((num_iter + 1,x.shape[0],x.shape[1]))\n",
    "    X[0] = x\n",
    "    loss = np.zeros(num_iter+1)\n",
    "    loss[0] = im_norm(p-x)\n",
    "    TMu = np.zeros(num_iter)\n",
    "    LL = np.zeros(num_iter)\n",
    "    AL = np.zeros(num_iter)\n",
    "    FF = np.zeros(num_iter)\n",
    "    FwL = np.zeros(num_iter)\n",
    "    AdL = np.zeros(num_iter)\n",
    "    for i in range(num_iter):\n",
    "        x_old = x\n",
    "        x = step_op(x,F_abl(x))\n",
    "        X[i+1] = x\n",
    "        loss[i+1] = im_norm(p-x)\n",
    "        grad_F = F_true_abl(x_old)\n",
    "        TMu[i] = im_norm(grad_F)\n",
    "        LL[i] = L(x_old)-L(x)\n",
    "        AL[i] = mu*(sp(grad_F,F_abl(x_old))/TMu[i]**2)\n",
    "        FF[i] = im_norm(F_true_abl(x_old)-F_abl(x_old))\n",
    "        FwL[i] = im_norm(true_op(x)-test_op(x))\n",
    "        r = test_op(x)-y_e\n",
    "        AdL[i] = im_norm(true_op.adjoint(r)-test_op.adjoint(r))\n",
    "    X = X[np.arange(9,num_iter,10)]\n",
    "    return {'X':X,'loss':loss,'TMu':TMu,'LL':LL,'AL':AL,'FF':FF,'FwL':FwL,'AdL':AdL}\n",
    "\n",
    "def save_plot_Test(path,dic,background = {},show = False):\n",
    "    fig,axs = plots(2,1,3/2)\n",
    "    axs[0].set_title('reconstruction loss')\n",
    "    axs[0].plot(background.get('static',[]),label = 'static')\n",
    "    axs[0].plot(background.get('true',[]),label = 'true')\n",
    "    axs[0].plot(dic.get('loss',[]),label = 'cor')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title('alignement')\n",
    "    axs[1].plot(dic.get('LL')/dic.get('TM')**2,label='LL')\n",
    "    axs[1].plot(dic.get('AL')/dic.get('TM')**2,label='AL')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].legend()\n",
    "    fig.savefig(path)\n",
    "    if show:\n",
    "        plt.show(fig)\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "class net_cor_op():\n",
    "    def __init__(self,static_op,fw_model,fw_swaped,adjoint_model,adj_swaped,device) -> None:\n",
    "        \"\"\"creates a operator \n",
    "\n",
    "        Args:\n",
    "            static_op (_type_): _description_\n",
    "            fw_model (_type_): _description_\n",
    "            fw_swaped (_type_): _description_\n",
    "            adjoint_model (_type_): _description_\n",
    "            adj_swaped (_type_): _description_\n",
    "            device (_type_): _description_\n",
    "        \"\"\"\n",
    "        self.cor_op = get_net_corected_operator(static_op, fw_model,device = device,swaped=fw_swaped)\n",
    "        self.cor_adj_op = get_net_corected_operator(static_op.adjoint, adjoint_model,device = device,swaped=adj_swaped)\n",
    "    def __call__(self, x) -> np.array:\n",
    "        \"\"\"returns the forward operator\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.array: _description_\n",
    "        \"\"\"\n",
    "        return self.cor_op(x)\n",
    "    def adjoint(self, x) -> np.array:\n",
    "        \"\"\"returns the adjoint of the opearator\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.array: _description_\n",
    "        \"\"\"\n",
    "        return self.cor_adj_op(x)\n",
    "\n",
    "def soft_shrink(x,alpha):\n",
    "    \"\"\"the soft shrinkige operator\n",
    "    Args:\n",
    "        x (np.array): input\n",
    "        alpha ( float ): parameter\n",
    "\n",
    "    Returns:\n",
    "        np.array: soft_schrink(x)\n",
    "    \"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x)-alpha,0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFehler beim Herstellen einer Verbindung mit dem Remote-Jupyter-Server „http://127.0.0.1:8888/“. Vergewissern Sie sich, dass der Server ausgeführt wird und erreichbar ist. (request to http://127.0.0.1:8888/api/kernels?1663595290681 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "np.cos(60/(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "gpu_idx = 0\n",
    "device = f\"cuda:{gpu_idx}\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "import astra\n",
    "astra.set_gpu_index(gpu_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_static_s = sparse.load_npz('Matritzen/64_64_256_96_static.npz')\n",
    "x_res = 64\n",
    "y_res = 64\n",
    "num_angles = 256\n",
    "detector_points = 96\n",
    "static_op = get_op(A_static_s,x_res, y_res, num_angles, detector_points)\n",
    "static_ray_trafo = get_static_ray_trafo(x_res, y_res,num_angles,detector_points,detector_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = np.load(file='phantoms/test_phantoms_64_1.npy')\n",
    "p = tp[0,:,:]\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_0is0(y):\n",
    "    return np.zeros((x_res,y_res))\n",
    "def x_0isATy(y):\n",
    "    return static_op.adjoint(y)\n",
    "def x_0isp(y):\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = ['Test']\n",
    "operator_list = []\n",
    "op_name_list = []\n",
    "i = 10\n",
    "A_u = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/u_ray_trafo_{i}.npz\")\n",
    "u_op = get_op(A_u,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $u$ shift')\n",
    "A_v = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/v_ray_trafo_{i}.npz\")\n",
    "v_op = get_op(A_v,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $v$ shift')\n",
    "A_u_v = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/u_v_ray_trafo_{i}.npz\")\n",
    "u_v_op = get_op(A_u_v,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift')\n",
    "shift_params = np.load(f'Matritzen/64_64_256_96_1_u_and_v_shift/shift_params_{i}.npy')\n",
    "\n",
    "A_s = sparse.load_npz('Matritzen/Test_ray_trafo_64_256_96_100.npz')\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift, new')\n",
    "A_s = sparse.load_npz('Matritzen/64_64_256_96_strong_u_v_shift.npz')\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift, new large amplitude')\n",
    "A_s = sparse.load_npz(\"Matritzen/Test_64_256_96_5addet_u_v.npz\")\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=5$, $u$ and $v$ shift, new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odl\n",
    "R = odl.solvers.Huber(static_ray_trafo.domain,0.001)\n",
    "grad_R = lambda x :R.gradient(x).asarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = config('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test',\n",
       " 'run_20220828_matrix_ISTA',\n",
       " 'run_20220828_matrix_ISTA_2',\n",
       " 'run_20220829_matrix_ISTA',\n",
       " 'run_20220830_matrix_ISTA',\n",
       " 'run_20220830_matrix_GD',\n",
       " 'run_20220831_matrix_GD',\n",
       " 'run_20220826_matrix_ISTA',\n",
       " 'run_20220901_matrix_ISTA',\n",
       " 'run_20220902_matrix_ISTA',\n",
       " 'run_20220902_matrix_ISTA_2',\n",
       " 'run_20220902_matrix_ISTA_3',\n",
       " 'run_20220903_matrix_ISTA',\n",
       " 'run_20220904_matrix_ISTA',\n",
       " 'run_20220904_matrix_ISTA_2',\n",
       " 'run_20220905_matrix_ISTA',\n",
       " 'run_20220905_matrix_ISTA_2',\n",
       " 'run_20220906_matrix_GD',\n",
       " 'run_20220908_matrix_ISTA',\n",
       " 'run_20220912_matrix_ISTA',\n",
       " 'run_20220913_matrix_ISTA',\n",
       " 'run_20220822_matrix_ISTA',\n",
       " 'run_20220823_matrix_ISTA',\n",
       " 'run_20220824_matrix_ISTA',\n",
       " 'run_20220825_matrix_ISTA']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./runs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './eval_dictionaries/'\n",
    "check_path(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = ['run_20220822_matrix_ISTA',\n",
    " 'run_20220823_matrix_ISTA',\n",
    " 'run_20220824_matrix_ISTA',\n",
    " 'run_20220825_matrix_ISTA',\n",
    " 'run_20220826_matrix_ISTA',\n",
    " 'run_20220902_matrix_ISTA_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 100\n",
    "for i,op in enumerate(operator_list):\n",
    "    y_e = error_for_y(op(p),e_p=0.01)\n",
    "    op_name = op_name_list[i]\n",
    "    ### ISTA ###\n",
    "    L = lambda x :1/(2*lam)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "    mu = 0.0002\n",
    "    lam = 0.001 \n",
    "    step_op = lambda x,grad_F_x : soft_shrink(x-mu/lam*grad_F_x,mu)\n",
    "    Zero = lambda x: np.zeros_like(x)\n",
    "    params = f'mu{mu}lam{lam}'.replace('.','_')\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name + params+'_ISTA' +'_x_0adj',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name + params+'_ISTA' +'_x_00',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_0adj',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_00',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "    \n",
    "\n",
    "    # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "    # mu = 0.2\n",
    "    # lam = 0.001 \n",
    "    # step_op = lambda x,grad_F_x : soft_shrink(x-mu*grad_F_x,lam*mu)\n",
    "    # Zero = lambda x: np.zeros_like(x)\n",
    "    \n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "\n",
    "            \n",
    "    # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "    # mu = 0.2\n",
    "    # lam = 0.001\n",
    "    # step_op = lambda x,grad_F_x : x-mu*(grad_F_x+lam*grad_R(x))\n",
    "    \n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "        \n",
    "    for run in runs_list:\n",
    "        c = config(run)\n",
    "\n",
    "        TA_static_s = torch.sparse_csr_tensor(A_static_s.indptr,A_static_s.indices,A_static_s.data,A_static_s.shape,dtype=float)\n",
    "        fw_model = select_fwd_model_type(c,TA_static_s.to_dense().to(device))\n",
    "        AT_static_s = sparse.csr_matrix(A_static_s.T)\n",
    "        TAT_static_s = torch.sparse_csr_tensor(AT_static_s.indptr,AT_static_s.indices,AT_static_s.data,AT_static_s.shape,dtype=float)\n",
    "        adj_model = select_adj_model_type(c,TAT_static_s.to_dense().to(device))\n",
    "        a = '_iter_49'#'last'#'iter_46'\n",
    "        fw_model.load_state_dict(torch.load(c.model_path + 'model' + a,map_location=device))\n",
    "        adj_model.load_state_dict(torch.load(c.model_path + 'adjoint_model' + a,map_location=device))\n",
    "        fw_model = fw_model.to(device)\n",
    "        adj_model = adj_model.to(device)\n",
    "        cor_op = net_cor_op(static_op,fw_model,c.forward_swaped,adj_model,c.adj_swaped,device)\n",
    "    \n",
    "        ### ISTA ###\n",
    "        L = lambda x :1/(2*lam)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "        mu = 0.0002\n",
    "        lam = 0.001 \n",
    "        step_op = lambda x,grad_F_x : soft_shrink(x-mu/lam*grad_F_x,mu)\n",
    "        Zero = lambda x: np.zeros_like(x)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_0adj',dic)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_00',dic)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "\n",
    "        \n",
    "\n",
    "        # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "        # mu = 0.2\n",
    "        # lam = 0.001 \n",
    "        # step_op = lambda x,grad_F_x : soft_shrink(x-mu*grad_F_x,lam*mu)\n",
    "        # Zero = lambda x: np.zeros_like(x)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "\n",
    "\n",
    "                \n",
    "        # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "        # mu = 0.2\n",
    "        # lam = 0.001\n",
    "        # step_op = lambda x,grad_F_x : x-mu*(grad_F_x+lam*grad_R(x))\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = np.load('./eval_dictionaries/run_20220822_matrix_ISTA_$n=1$, $u$ and $v$ shift, new large amplitude_GD_Huber_x_00.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0822', '0823', '0824', '0825', '0826']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(22,27):\n",
    "    l.append(f'08{i}')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic_path in os.listdir(save_path):\n",
    "\n",
    "    if not dic_path.startswith('static') and not dic_path.startswith('true') and dic_path.startswith('run_20220822_matrix_ISTA'):\n",
    "        \n",
    "        fig,axs = plots(2,4,1,10)\n",
    "        fig.suptitle(rf'{dic_path.split(\"run_20220822_matrix_ISTA_\")[1].replace(\"_\",\" \")}')\n",
    "        \n",
    "        static_dic=dic = np.load(save_path+'static' +dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        true_dic=dic = np.load(save_path+'true'+dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        axs[1,1].set_title('static operator')\n",
    "        axs[1,1].imshow(static_dic.get('X')[-1])\n",
    "        axs[1,2].set_title('precise operator')\n",
    "        axs[1,2].imshow(true_dic.get('X')[-1])\n",
    "        axs[1,0].plot(static_dic.get('loss'),label='static_op')\n",
    "        axs[1,0].plot(true_dic.get('loss'),label='precise operator')\n",
    "        for i,n in enumerate(['0822', '0823', '0824', '0825']):\n",
    "            dic = np.load(save_path+dic_path.split('0822')[0] +n + dic_path.split('0822')[1],allow_pickle=True).item()\n",
    "            axs[0,i].imshow(dic.get('X')[-1])\n",
    "            axs[0,i].set_title(n)\n",
    "            axs[1,0].plot(dic.get('loss'),label=n)\n",
    "        axs[1,0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic_path in os.listdir(save_path):\n",
    "\n",
    "    if not dic_path.startswith('static') and not dic_path.startswith('true') and dic_path.startswith('run_20220822_matrix_ISTA')  and '_ISTA_x_0' in dic_path:\n",
    "        \n",
    "        fig,axs = plots(2,4,1,4)\n",
    "        fig.suptitle(rf'{dic_path.split(\"run_20220822_matrix_ISTA_\")[1].replace(\"_\",\" \")}')\n",
    "        \n",
    "        static_dic=dic = np.load(save_path+'static' + dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        true_dic=dic = np.load(save_path+'true'+dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        axs[1,1].set_title('static operator')\n",
    "        axs[1,1].imshow(static_dic.get('X')[-1])\n",
    "        axs[1,2].set_title('precise operator')\n",
    "        axs[1,2].imshow(true_dic.get('X')[-1])\n",
    "        axs[1,3].set_title('original')\n",
    "        axs[1,3].imshow(p)\n",
    "        axs[1,0].plot(static_dic.get('loss'),label='static_op')\n",
    "        axs[1,0].plot(true_dic.get('loss'),label='precise operator')\n",
    "        for i,n in enumerate(['0822', '0823', '0824', '0825']):\n",
    "            m = [r'cor. before ops',r'cor in $X$',r'cor.after ops',r'cor in $Y$'][i]\n",
    "            dic = np.load(save_path+dic_path.split('0822')[0] +n + dic_path.split('0822')[1],allow_pickle=True).item()\n",
    "            axs[0,i].imshow(dic.get('X')[-1])\n",
    "            axs[0,i].set_title(m)\n",
    "            axs[1,0].plot(dic.get('loss'),label=m)\n",
    "        axs[1,0].legend()\n",
    "        axs[1,0].set_yscale('log')\n",
    "        fig.set_dpi(300)\n",
    "        fig.savefig('./Bilder/'+ dic_path.split('.npy')[0].replace(',','').replace('$','').replace(' ','_').replace('=','') +'.png')\n",
    "        plt.show(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_20220902_matrix_ISTA_2_$n=5$, $u$ and $v$ shift, new_GD_Huber_x_0p.npy'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dic_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_20220822_matrix_ISTA_$n=5$, $u$ and $v$ shift, new_GD_Huber_x_0p_static'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split('0826')[0] + '0822'+ a.split('0826')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run 20220826 matrix ISTA $n=5$, $u$ and $v$ shift, new GD Huber x 0p static'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$n=5$, $u$ and $v$ shift, new_GD_Huber_x_0p_static'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split('run_20220826_matrix_ISTA_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.],\n",
       "        [ 0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.],\n",
       "        [ 0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.],\n",
       "        [ 0.,  0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, (2,2)[0],(2,2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f39ee474640>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "mu = 0.2\n",
    "lam = 0.0001\n",
    "y_e = error_for_y(op(p),e_p=0.01)\n",
    "step_op = lambda x,grad_F_x : soft_shrink(x-mu*(grad_F_x+lam*64*grad_R(x)),mu*lam)\n",
    "\n",
    "dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter=500)\n",
    "plt.plot(dic.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.333333333333336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50*40/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.ones((100,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[np.arange(9,100,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88a9da9d68497d7f521781f00a73fecd7a3c53060cd82ab5fb1b1b3aae3c56d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
