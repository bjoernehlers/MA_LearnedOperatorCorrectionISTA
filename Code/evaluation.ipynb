{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sript was used for the evalution of the models for the Mastar thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ray_transforms import get_ray_trafo, get_static_ray_trafo\n",
    "from test_model_functions_swaped import get_net_corected_operator\n",
    "# import random\n",
    "import torch \n",
    "\n",
    "\n",
    "import os\n",
    "from conf import config\n",
    "from select_model_type_matrix import select_fwd_model_type,select_adj_model_type\n",
    "from scipy import sparse\n",
    "from util import get_op,Mat,plots,rand_shift_params,error_for_y,check_path\n",
    "\n",
    "def im_norm(x):\n",
    "    x = x.reshape(x.size)\n",
    "    return np.linalg.norm(x,2)\n",
    "\n",
    "def sp(a,b):\n",
    "    return a.reshape(a.size)@b.reshape(b.size)\n",
    "\n",
    "def ISTA_obj_func(op,y,lam,x):\n",
    "    return 1/(2*lam)*np.linalg.norm((op(x)-y).reshape(y.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "\n",
    "def Test_PGM(step_op,L,grad_R,true_op,p,y_e,x_0_selector,test_op,mu,num_iter):\n",
    "    F_abl = lambda x: test_op.adjoint(test_op(x)-y_e) + grad_R(x)\n",
    "    F_true_abl = lambda x: true_op.adjoint(true_op(x)-y_e) + grad_R(x)\n",
    "    x = x_0_selector(y_e)\n",
    "    X = np.zeros((num_iter + 1,x.shape[0],x.shape[1]))\n",
    "    X[0] = x\n",
    "    loss = np.zeros(num_iter+1)\n",
    "    loss[0] = im_norm(p-x)\n",
    "    TThetaMu = np.zeros(num_iter)\n",
    "    LL = np.zeros(num_iter)\n",
    "    AL = np.zeros(num_iter)\n",
    "    FwL = np.zeros(num_iter)\n",
    "    AdL = np.zeros(num_iter)\n",
    "    for i in range(num_iter):\n",
    "        x_old = x\n",
    "        x = step_op(x,F_abl(x))\n",
    "        X[i+1] = x\n",
    "        loss[i+1] = im_norm(p-x)\n",
    "        T_Thetamu = (x_old-x)/(mu)\n",
    "        TThetaMu[i] = im_norm(T_Thetamu)\n",
    "        LL[i] = L(x_old)-L(x)\n",
    "        AL[i] = mu*(sp(F_true_abl(x_old)-F_abl(x_old),T_Thetamu)+0.5*TThetaMu[i]**2)\n",
    "        FwL[i] = im_norm(true_op(x)-test_op(x))\n",
    "        r = test_op(x)-y_e\n",
    "        AdL[i] = im_norm(true_op.adjoint(r)-test_op.adjoint(r))\n",
    "    X = X[np.arange(9,num_iter,10)]\n",
    "    return {'X':X,'loss':loss,'TThetaMu':TThetaMu,'LL':LL,'AL':AL,'FwL':FwL,'AdL':AdL}\n",
    "\n",
    "def Test_GD(step_op,L,grad_R,true_op,p,y_e,x_0_selector,test_op,mu,num_iter):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        step_op (_type_): an operator that produces the next iteration x_k+1 = step_op(x_k,F(x_k))\n",
    "        L (_type_): The objective function that is minimized for testing only\n",
    "        grad_R (_type_): the differentialle part of the regularization terms\n",
    "        true_op (_type_): the precise operator we try to achieve\n",
    "        p (_type_): the phantom\n",
    "        y_e (_type_): noisy data\n",
    "        x_0_selector (_type_): function that gives the x_0 deppending on y_e\n",
    "        test_op (_type_): the operaator we want to test\n",
    "        adj_test_op (_type_): the adjoint of the test opeartor\n",
    "        mu (_type_): constant step size for \n",
    "        num_iter (_type_): number of iterations taht are being computed\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\" \n",
    "    F_abl = lambda x: test_op.adjoint(test_op(x)-y_e) + grad_R(x)\n",
    "    F_true_abl = lambda x: true_op.adjoint(true_op(x)-y_e) + grad_R(x)\n",
    "    x = x_0_selector(y_e)\n",
    "    X = np.zeros((num_iter + 1,x.shape[0],x.shape[1]))\n",
    "    X[0] = x\n",
    "    loss = np.zeros(num_iter+1)\n",
    "    loss[0] = im_norm(p-x)\n",
    "    TMu = np.zeros(num_iter)\n",
    "    LL = np.zeros(num_iter)\n",
    "    AL = np.zeros(num_iter)\n",
    "    FF = np.zeros(num_iter)\n",
    "    FwL = np.zeros(num_iter)\n",
    "    AdL = np.zeros(num_iter)\n",
    "    for i in range(num_iter):\n",
    "        x_old = x\n",
    "        x = step_op(x,F_abl(x))\n",
    "        X[i+1] = x\n",
    "        loss[i+1] = im_norm(p-x)\n",
    "        grad_F = F_true_abl(x_old)\n",
    "        TMu[i] = im_norm(grad_F)\n",
    "        LL[i] = L(x_old)-L(x)\n",
    "        AL[i] = mu*(sp(grad_F,F_abl(x_old))/TMu[i]**2)\n",
    "        FF[i] = im_norm(F_true_abl(x_old)-F_abl(x_old))\n",
    "        FwL[i] = im_norm(true_op(x)-test_op(x))\n",
    "        r = test_op(x)-y_e\n",
    "        AdL[i] = im_norm(true_op.adjoint(r)-test_op.adjoint(r))\n",
    "    X = X[np.arange(9,num_iter,10)]\n",
    "    return {'X':X,'loss':loss,'TMu':TMu,'LL':LL,'AL':AL,'FF':FF,'FwL':FwL,'AdL':AdL}\n",
    "\n",
    "def save_plot_Test(path,dic,background = {},show = False):\n",
    "    fig,axs = plots(2,1,3/2)\n",
    "    axs[0].set_title('reconstruction loss')\n",
    "    axs[0].plot(background.get('static',[]),label = 'static')\n",
    "    axs[0].plot(background.get('true',[]),label = 'true')\n",
    "    axs[0].plot(dic.get('loss',[]),label = 'cor')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title('alignement')\n",
    "    axs[1].plot(dic.get('LL')/dic.get('TM')**2,label='LL')\n",
    "    axs[1].plot(dic.get('AL')/dic.get('TM')**2,label='AL')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].legend()\n",
    "    fig.savefig(path)\n",
    "    if show:\n",
    "        plt.show(fig)\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "class net_cor_op():\n",
    "    def __init__(self,static_op,fw_model,fw_swaped,adjoint_model,adj_swaped,device) -> None:\n",
    "        \"\"\"creates a operator \n",
    "\n",
    "        Args:\n",
    "            static_op (_type_): _description_\n",
    "            fw_model (_type_): _description_\n",
    "            fw_swaped (_type_): _description_\n",
    "            adjoint_model (_type_): _description_\n",
    "            adj_swaped (_type_): _description_\n",
    "            device (_type_): _description_\n",
    "        \"\"\"\n",
    "        self.cor_op = get_net_corected_operator(static_op, fw_model,device = device,swaped=fw_swaped)\n",
    "        self.cor_adj_op = get_net_corected_operator(static_op.adjoint, adjoint_model,device = device,swaped=adj_swaped)\n",
    "    def __call__(self, x) -> np.array:\n",
    "        \"\"\"returns the forward operator\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.array: _description_\n",
    "        \"\"\"\n",
    "        return self.cor_op(x)\n",
    "    def adjoint(self, x) -> np.array:\n",
    "        \"\"\"returns the adjoint of the opearator\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.array: _description_\n",
    "        \"\"\"\n",
    "        return self.cor_adj_op(x)\n",
    "\n",
    "def soft_shrink(x,alpha):\n",
    "    \"\"\"the soft shrinkige operator\n",
    "    Args:\n",
    "        x (np.array): input\n",
    "        alpha ( float ): parameter\n",
    "\n",
    "    Returns:\n",
    "        np.array: soft_schrink(x)\n",
    "    \"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x)-alpha,0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFehler beim Herstellen einer Verbindung mit dem Remote-Jupyter-Server „http://127.0.0.1:8888/“. Vergewissern Sie sich, dass der Server ausgeführt wird und erreichbar ist. (request to http://127.0.0.1:8888/api/kernels?1663595290681 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "np.cos(60/(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "gpu_idx = 0\n",
    "device = f\"cuda:{gpu_idx}\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "import astra\n",
    "astra.set_gpu_index(gpu_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_static_s = sparse.load_npz('Matritzen/64_64_256_96_static.npz')\n",
    "x_res = 64\n",
    "y_res = 64\n",
    "num_angles = 256\n",
    "detector_points = 96\n",
    "static_op = get_op(A_static_s,x_res, y_res, num_angles, detector_points)\n",
    "static_ray_trafo = get_static_ray_trafo(x_res, y_res,num_angles,detector_points,detector_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = np.load(file='phantoms/test_phantoms_64_1.npy')\n",
    "p = tp[0,:,:]\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_0is0(y):\n",
    "    return np.zeros((x_res,y_res))\n",
    "def x_0isATy(y):\n",
    "    return static_op.adjoint(y)\n",
    "def x_0isp(y):\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = ['Test']\n",
    "operator_list = []\n",
    "op_name_list = []\n",
    "i = 10\n",
    "A_u = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/u_ray_trafo_{i}.npz\")\n",
    "u_op = get_op(A_u,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $u$ shift')\n",
    "A_v = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/v_ray_trafo_{i}.npz\")\n",
    "v_op = get_op(A_v,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $v$ shift')\n",
    "A_u_v = sparse.load_npz(f\"Matritzen/64_64_256_96_1_u_and_v_shift/u_v_ray_trafo_{i}.npz\")\n",
    "u_v_op = get_op(A_u_v,x_res, y_res, num_angles, detector_points)\n",
    "operator_list.append(u_op)\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift')\n",
    "shift_params = np.load(f'Matritzen/64_64_256_96_1_u_and_v_shift/shift_params_{i}.npy')\n",
    "\n",
    "A_s = sparse.load_npz('Matritzen/Test_ray_trafo_64_256_96_100.npz')\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift, new')\n",
    "A_s = sparse.load_npz('Matritzen/64_64_256_96_strong_u_v_shift.npz')\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=1$, $u$ and $v$ shift, new large amplitude')\n",
    "A_s = sparse.load_npz(\"Matritzen/Test_64_256_96_5addet_u_v.npz\")\n",
    "operator_list.append(get_op(A_s,x_res, y_res, num_angles, detector_points))\n",
    "op_name_list.append(r'$n=5$, $u$ and $v$ shift, new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odl\n",
    "R = odl.solvers.Huber(static_ray_trafo.domain,0.001)\n",
    "grad_R = lambda x :R.gradient(x).asarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = config('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test',\n",
       " 'run_20220828_matrix_ISTA',\n",
       " 'run_20220828_matrix_ISTA_2',\n",
       " 'run_20220829_matrix_ISTA',\n",
       " 'run_20220830_matrix_ISTA',\n",
       " 'run_20220830_matrix_GD',\n",
       " 'run_20220831_matrix_GD',\n",
       " 'run_20220826_matrix_ISTA',\n",
       " 'run_20220901_matrix_ISTA',\n",
       " 'run_20220902_matrix_ISTA',\n",
       " 'run_20220902_matrix_ISTA_2',\n",
       " 'run_20220902_matrix_ISTA_3',\n",
       " 'run_20220903_matrix_ISTA',\n",
       " 'run_20220904_matrix_ISTA',\n",
       " 'run_20220904_matrix_ISTA_2',\n",
       " 'run_20220905_matrix_ISTA',\n",
       " 'run_20220905_matrix_ISTA_2',\n",
       " 'run_20220906_matrix_GD',\n",
       " 'run_20220908_matrix_ISTA',\n",
       " 'run_20220912_matrix_ISTA',\n",
       " 'run_20220913_matrix_ISTA',\n",
       " 'run_20220822_matrix_ISTA',\n",
       " 'run_20220823_matrix_ISTA',\n",
       " 'run_20220824_matrix_ISTA',\n",
       " 'run_20220825_matrix_ISTA']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./runs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './eval_dictionaries/'\n",
    "check_path(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = ['run_20220822_matrix_ISTA',\n",
    " 'run_20220823_matrix_ISTA',\n",
    " 'run_20220824_matrix_ISTA',\n",
    " 'run_20220825_matrix_ISTA',\n",
    " 'run_20220826_matrix_ISTA',\n",
    " 'run_20220902_matrix_ISTA_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 100\n",
    "for i,op in enumerate(operator_list):\n",
    "    y_e = error_for_y(op(p),e_p=0.01)\n",
    "    op_name = op_name_list[i]\n",
    "    ### ISTA ###\n",
    "    L = lambda x :1/(2*lam)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "    mu = 0.0002\n",
    "    lam = 0.001 \n",
    "    step_op = lambda x,grad_F_x : soft_shrink(x-mu/lam*grad_F_x,mu)\n",
    "    Zero = lambda x: np.zeros_like(x)\n",
    "    params = f'mu{mu}lam{lam}'.replace('.','_')\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name + params+'_ISTA' +'_x_0adj',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name + params+'_ISTA' +'_x_00',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    np.save(save_path+'true_'+op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_0adj',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_00',dic)\n",
    "    dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    np.save(save_path+'static_'+ op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "    \n",
    "\n",
    "    # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "    # mu = 0.2\n",
    "    # lam = 0.001 \n",
    "    # step_op = lambda x,grad_F_x : soft_shrink(x-mu*grad_F_x,lam*mu)\n",
    "    # Zero = lambda x: np.zeros_like(x)\n",
    "    \n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "    # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "\n",
    "            \n",
    "    # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "    # mu = 0.2\n",
    "    # lam = 0.001\n",
    "    # step_op = lambda x,grad_F_x : x-mu*(grad_F_x+lam*grad_R(x))\n",
    "    \n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,op,mu,num_iter)\n",
    "    # np.save(save_path+'true_'+op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "    # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,static_op,mu,num_iter)\n",
    "    # np.save(save_path+'static_'+ op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "        \n",
    "    for run in runs_list:\n",
    "        c = config(run)\n",
    "\n",
    "        TA_static_s = torch.sparse_csr_tensor(A_static_s.indptr,A_static_s.indices,A_static_s.data,A_static_s.shape,dtype=float)\n",
    "        fw_model = select_fwd_model_type(c,TA_static_s.to_dense().to(device))\n",
    "        AT_static_s = sparse.csr_matrix(A_static_s.T)\n",
    "        TAT_static_s = torch.sparse_csr_tensor(AT_static_s.indptr,AT_static_s.indices,AT_static_s.data,AT_static_s.shape,dtype=float)\n",
    "        adj_model = select_adj_model_type(c,TAT_static_s.to_dense().to(device))\n",
    "        a = '_iter_49'#'last'#'iter_46'\n",
    "        fw_model.load_state_dict(torch.load(c.model_path + 'model' + a,map_location=device))\n",
    "        adj_model.load_state_dict(torch.load(c.model_path + 'adjoint_model' + a,map_location=device))\n",
    "        fw_model = fw_model.to(device)\n",
    "        adj_model = adj_model.to(device)\n",
    "        cor_op = net_cor_op(static_op,fw_model,c.forward_swaped,adj_model,c.adj_swaped,device)\n",
    "    \n",
    "        ### ISTA ###\n",
    "        L = lambda x :1/(2*lam)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+np.linalg.norm(x.reshape(x.size),1)\n",
    "        mu = 0.0002\n",
    "        lam = 0.001 \n",
    "        step_op = lambda x,grad_F_x : soft_shrink(x-mu/lam*grad_F_x,mu)\n",
    "        Zero = lambda x: np.zeros_like(x)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_0adj',dic)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_00',dic)\n",
    "        dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        np.save(save_path+run+'_'+op_name+ params+'_ISTA' +'_x_0p',dic)\n",
    "\n",
    "        \n",
    "\n",
    "        # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "        # mu = 0.2\n",
    "        # lam = 0.001 \n",
    "        # step_op = lambda x,grad_F_x : soft_shrink(x-mu*grad_F_x,lam*mu)\n",
    "        # Zero = lambda x: np.zeros_like(x)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_0adj',dic)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_00',dic)\n",
    "        # dic = Test_PGM(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_ISTAlam' +'_x_0p',dic)\n",
    "\n",
    "\n",
    "                \n",
    "        # L = lambda x :1/(2)*np.linalg.norm((op(x)-y_e).reshape(y_e.size),2)**2+lam*np.linalg.norm(x.reshape(x.size),1)\n",
    "        # mu = 0.2\n",
    "        # lam = 0.001\n",
    "        # step_op = lambda x,grad_F_x : x-mu*(grad_F_x+lam*grad_R(x))\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isATy,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_0adj',dic)\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0is0,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_00',dic)\n",
    "        # dic = Test_GD(step_op,L,Zero,op,p,y_e,x_0isp,cor_op,mu,num_iter)\n",
    "        # np.save(save_path+run+'_'+op_name+ params+'_GD_Huber' +'_x_0p',dic)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = np.load('./eval_dictionaries/run_20220822_matrix_ISTA_$n=1$, $u$ and $v$ shift, new large amplitude_GD_Huber_x_00.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0822', '0823', '0824', '0825', '0826']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(22,27):\n",
    "    l.append(f'08{i}')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic_path in os.listdir(save_path):\n",
    "\n",
    "    if not dic_path.startswith('static') and not dic_path.startswith('true') and dic_path.startswith('run_20220822_matrix_ISTA'):\n",
    "        \n",
    "        fig,axs = plots(2,4,1,10)\n",
    "        fig.suptitle(rf'{dic_path.split(\"run_20220822_matrix_ISTA_\")[1].replace(\"_\",\" \")}')\n",
    "        \n",
    "        static_dic=dic = np.load(save_path+'static' +dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        true_dic=dic = np.load(save_path+'true'+dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        axs[1,1].set_title('static operator')\n",
    "        axs[1,1].imshow(static_dic.get('X')[-1])\n",
    "        axs[1,2].set_title('precise operator')\n",
    "        axs[1,2].imshow(true_dic.get('X')[-1])\n",
    "        axs[1,0].plot(static_dic.get('loss'),label='static_op')\n",
    "        axs[1,0].plot(true_dic.get('loss'),label='precise operator')\n",
    "        for i,n in enumerate(['0822', '0823', '0824', '0825']):\n",
    "            dic = np.load(save_path+dic_path.split('0822')[0] +n + dic_path.split('0822')[1],allow_pickle=True).item()\n",
    "            axs[0,i].imshow(dic.get('X')[-1])\n",
    "            axs[0,i].set_title(n)\n",
    "            axs[1,0].plot(dic.get('loss'),label=n)\n",
    "        axs[1,0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic_path in os.listdir(save_path):\n",
    "\n",
    "    if not dic_path.startswith('static') and not dic_path.startswith('true') and dic_path.startswith('run_20220822_matrix_ISTA')  and '_ISTA_x_0' in dic_path:\n",
    "        \n",
    "        fig,axs = plots(2,4,1,4)\n",
    "        fig.suptitle(rf'{dic_path.split(\"run_20220822_matrix_ISTA_\")[1].replace(\"_\",\" \")}')\n",
    "        \n",
    "        static_dic=dic = np.load(save_path+'static' + dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        true_dic=dic = np.load(save_path+'true'+dic_path.split('run_20220822_matrix_ISTA')[1],allow_pickle=True).item()\n",
    "        axs[1,1].set_title('static operator')\n",
    "        axs[1,1].imshow(static_dic.get('X')[-1])\n",
    "        axs[1,2].set_title('precise operator')\n",
    "        axs[1,2].imshow(true_dic.get('X')[-1])\n",
    "        axs[1,3].set_title('original')\n",
    "        axs[1,3].imshow(p)\n",
    "        axs[1,0].plot(static_dic.get('loss'),label='static_op')\n",
    "        axs[1,0].plot(true_dic.get('loss'),label='precise operator')\n",
    "        for i,n in enumerate(['0822', '0823', '0824', '0825']):\n",
    "            m = [r'cor. before ops',r'cor in $X$',r'cor.after ops',r'cor in $Y$'][i]\n",
    "            dic = np.load(save_path+dic_path.split('0822')[0] +n + dic_path.split('0822')[1],allow_pickle=True).item()\n",
    "            axs[0,i].imshow(dic.get('X')[-1])\n",
    "            axs[0,i].set_title(m)\n",
    "            axs[1,0].plot(dic.get('loss'),label=m)\n",
    "        axs[1,0].legend()\n",
    "        axs[1,0].set_yscale('log')\n",
    "        fig.set_dpi(300)\n",
    "        fig.savefig('./Bilder/'+ dic_path.split('.npy')[0].replace(',','').replace('$','').replace(' ','_').replace('=','') +'.png')\n",
    "        plt.show(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88a9da9d68497d7f521781f00a73fecd7a3c53060cd82ab5fb1b1b3aae3c56d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
